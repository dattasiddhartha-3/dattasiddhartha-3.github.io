---
title: "Music Generation through Food Detection, Assignment of Music Notes to Distinct Items, and Utensil Impact Detection"
excerpt: "An AR system where users put on a pair of goggles or a visualizer above highlights the food on the table, and users use their utensils to generate individualized music notes from tapping their food. "
collection: portfolio
---

[![IMAGE ALT TEXT](/images/armusic.png)](https://bit.ly/2UY9FM0)

This is an augmented reality system/game where people can see highlights (bounding boxes) over their food, and tapping their food will produce a certain instrumental sound to synthesize music (including guitar chords, piano on different scales, and drums); it executed on Mixed Reality lens with object detection

[Source code](https://bit.ly/2P7YYRQ)

Download the repository and run the objectdetection+airdrums-ver2.ipynb notebook to run the model.

Sample videos: 

[Demo 1](https://bit.ly/2GcKUCl)

[Demo 2](https://bit.ly/2UY9FM0)
